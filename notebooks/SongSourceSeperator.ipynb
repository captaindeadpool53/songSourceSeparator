{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/captaindeadpool53/songSourceSeperator/blob/main/notebooks/SongSourceSeperator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9rg4r1VBNOM",
        "outputId": "2f9be191-291c-4fbe-a4d9-b7ecf7aa8ab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5gVV4Uzm04v",
        "outputId": "99a0e0c4-2ba7-4939-ffee-3fc56d3cd11f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'songSourceSeperator'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 1123, done.\u001b[K\n",
            "remote: Counting objects: 100% (431/431), done.\u001b[K\n",
            "remote: Compressing objects: 100% (223/223), done.\u001b[K\n",
            "remote: Total 1123 (delta 245), reused 320 (delta 203), pack-reused 692\u001b[K\n",
            "Receiving objects: 100% (1123/1123), 53.86 MiB | 19.66 MiB/s, done.\n",
            "Resolving deltas: 100% (665/665), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone -l -s -b source_seperation_drums_v2_lazy_loading https://github.com/captaindeadpool53/songSourceSeperator.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTejKmr1ROru",
        "outputId": "eacb0092-5489-4fb7-8c6f-5ca2cfe91ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/songSourceSeperator\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "%cd songSourceSeperator\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# List available physical GPUs and check if GPUs are available\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Allow memory growth for each GPU\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjPd0uKKT3I2",
        "outputId": "4a20a730-6c38-48ec-bd40-abed7dd84638"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable mixed precision\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n"
      ],
      "metadata": {
        "id": "RZEU08VIUO2l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iuZNB0_MV43",
        "outputId": "83dfb843-8468-487a-f798-e9bfd59b34cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "::: Loading saved model weights :::\n",
            "::: Sucessfuly loaded saved model weights :::\n",
            "::: Beginning training :::\n",
            "Epoch 1/40\n",
            "    324/Unknown - 112s 198ms/step - loss: 37.9715\n",
            "Epoch 1: val_loss improved from inf to 36.44294, saving model to /content/drive/MyDrive/Colab Notebooks/songSourceSeperator/saved_models/modelCheckpoint.h5\n",
            "324/324 [==============================] - 196s 456ms/step - loss: 37.9715 - val_loss: 36.4429 - lr: 1.0000e-04\n",
            "Epoch 2/40\n",
            "324/324 [==============================] - ETA: 0s - loss: 37.9171\n",
            "Epoch 2: val_loss did not improve from 36.44294\n",
            "324/324 [==============================] - 140s 407ms/step - loss: 37.9171 - val_loss: 37.3243 - lr: 1.0000e-04\n",
            "Epoch 3/40\n",
            "324/324 [==============================] - ETA: 0s - loss: 37.9631\n",
            "Epoch 3: val_loss did not improve from 36.44294\n",
            "324/324 [==============================] - 143s 418ms/step - loss: 37.9631 - val_loss: 37.3839 - lr: 1.0000e-04\n",
            "Epoch 4/40\n",
            "324/324 [==============================] - ETA: 0s - loss: 37.9974\n",
            "Epoch 4: val_loss did not improve from 36.44294\n",
            "324/324 [==============================] - 142s 413ms/step - loss: 37.9974 - val_loss: 37.0082 - lr: 1.0000e-04\n",
            "Epoch 5/40\n",
            "324/324 [==============================] - ETA: 0s - loss: 37.9112\n",
            "Epoch 5: val_loss did not improve from 36.44294\n",
            "324/324 [==============================] - 143s 416ms/step - loss: 37.9112 - val_loss: 36.8086 - lr: 1.0000e-04\n",
            "Epoch 6/40\n",
            "324/324 [==============================] - ETA: 0s - loss: 37.9988\n",
            "Epoch 6: val_loss did not improve from 36.44294\n",
            "324/324 [==============================] - 140s 410ms/step - loss: 37.9988 - val_loss: 36.9953 - lr: 1.0000e-04\n",
            "Epoch 7/40\n",
            "324/324 [==============================] - ETA: 0s - loss: 38.0344\n",
            "Epoch 7: val_loss did not improve from 36.44294\n",
            "324/324 [==============================] - 142s 416ms/step - loss: 38.0344 - val_loss: 37.2960 - lr: 1.0000e-04\n",
            "Epoch 8/40\n",
            "324/324 [==============================] - ETA: 0s - loss: 37.9521\n",
            "Epoch 8: val_loss improved from 36.44294 to 36.28455, saving model to /content/drive/MyDrive/Colab Notebooks/songSourceSeperator/saved_models/modelCheckpoint.h5\n",
            "324/324 [==============================] - 141s 411ms/step - loss: 37.9521 - val_loss: 36.2845 - lr: 1.0000e-04\n",
            "Epoch 9/40\n",
            "324/324 [==============================] - ETA: 0s - loss: 37.9902\n",
            "Epoch 9: val_loss did not improve from 36.28455\n",
            "324/324 [==============================] - 139s 409ms/step - loss: 37.9902 - val_loss: 36.6215 - lr: 1.0000e-04\n",
            "Epoch 10/40\n",
            "324/324 [==============================] - ETA: 0s - loss: 37.9553\n",
            "Epoch 10: val_loss did not improve from 36.28455\n",
            "324/324 [==============================] - 158s 460ms/step - loss: 37.9553 - val_loss: 37.5450 - lr: 1.0000e-04\n",
            "Epoch 11/40\n",
            "324/324 [==============================] - ETA: 0s - loss: 37.8876\n",
            "Epoch 11: val_loss did not improve from 36.28455\n",
            "324/324 [==============================] - 155s 454ms/step - loss: 37.8876 - val_loss: 37.3276 - lr: 1.0000e-04\n",
            "Epoch 12/40\n",
            "324/324 [==============================] - ETA: 0s - loss: 37.9481\n",
            "Epoch 12: val_loss did not improve from 36.28455\n",
            "324/324 [==============================] - 143s 416ms/step - loss: 37.9481 - val_loss: 37.4810 - lr: 1.0000e-04\n",
            "Epoch 13/40\n",
            "324/324 [==============================] - ETA: 0s - loss: 37.9574\n",
            "Epoch 13: val_loss did not improve from 36.28455\n",
            "324/324 [==============================] - 143s 416ms/step - loss: 37.9574 - val_loss: 37.0580 - lr: 1.0000e-04\n",
            "Epoch 14/40\n",
            "324/324 [==============================] - ETA: 0s - loss: 37.9041"
          ]
        }
      ],
      "source": [
        "\"\"\"For dataset preprocessing, model training, and prediction\"\"\"\n",
        "import main\n",
        "%run main.py '/content/drive/MyDrive/Colab Notebooks/songSourceSeperator' 1e-4 0.2 1e-6 40 8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"For predicting using saved model weights\"\"\"\n",
        "from src.pipeline import PipelineHandler\n",
        "\n",
        "pipelineHandler = PipelineHandler(\n",
        "        FRAME_SIZE=2048,\n",
        "        HOP_LENGTH=256,\n",
        "        SEGMENT_LENGTH_IN_SECONDS=1.5,\n",
        "        SAMPLE_RATE=44100,\n",
        "        PROJECT_ROOT_PATH = '/content/drive/MyDrive/Colab Notebooks/songSourceSeperator',\n",
        "        BATCH_SIZE = 8\n",
        "    )\n",
        "pipelineHandler.predict()"
      ],
      "metadata": {
        "id": "sRWvzYE4wFql"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyNf4VBHPczw58N+8wWKHTJm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}